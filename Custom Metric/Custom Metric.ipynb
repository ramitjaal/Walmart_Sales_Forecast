{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    \n",
    "## Multiprocess Runs\n",
    "def df_parallelize_run(func, t_split):\n",
    "    num_cores = np.min([N_CORES,len(t_split)])\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Getting the scales and weights #############\n",
    "path = '/kaggle/input/m5-weights-and-scales/'\n",
    "\n",
    "def get_weights_scales_level_12(df, end_test, path):\n",
    "    # Gets the scale, weight, and scaled weight in a dataframe, \n",
    "    # aligned with the 'id' column of df\n",
    "\n",
    "    # Get the weights and scales for all the levels \n",
    "    wdf = pd.read_csv(f'{path}weight_scale_{end_test-27}.csv')\n",
    "    wdf['scaled_weight'] = wdf.weight/np.sqrt(wdf.scale)\n",
    "\n",
    "    # For this function, we just want level 12 weights and scales\n",
    "    wdf = wdf[wdf.Level_id == 'Level12']\n",
    "\n",
    "    # We make an 'id' column for easy merging, df must have 'id' column\n",
    "    wdf['id'] = wdf['Agg_Level_1'] + '_' +  wdf['Agg_Level_2'] + '_validation'\n",
    "\n",
    "    # Taking just he columns we want to use in the merge \n",
    "    wdf = wdf[['id', 'scale', 'weight', 'scaled_weight']]\n",
    "\n",
    "    # Merge with 'id' column of the df\n",
    "    wdf = pd.merge(df[['id']], wdf, on='id', how='left')\n",
    "    \n",
    "    return wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L12_WRMSSE(preds, actuals, p_horizon, num_products, scale, weight): \n",
    "    \n",
    "    actuals = actuals[-(p_horizon * num_products):]\n",
    "    preds = preds[-(p_horizon * num_products):]\n",
    "    diff = actuals - preds\n",
    "\n",
    "    # For WRMSSE with need square of the daily error and then get the appropriate scale\n",
    "    res = diff ** 2\n",
    "    res = res/scale.values\n",
    "\n",
    "    res = res\n",
    "    res = res.reshape(p_horizon, num_products)\n",
    "\n",
    "    res = res.mean(axis=0)\n",
    "    res = np.sqrt(res)\n",
    "\n",
    "    res = res * weight\n",
    "    res = res.sum()\n",
    "    return res\n",
    "################### Custom metric #####################\n",
    "def custom_metric(preds, train_data):\n",
    "    actuals = train_data.get_label()\n",
    "    res = L12_WRMSSE(preds, actuals, P_HORIZON, NUM_PRODUCTS, scale, weight)\n",
    "    return 'L12_WRMSSE', res, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
